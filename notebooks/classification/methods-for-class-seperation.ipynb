{"cells":[{"cell_type":"markdown","metadata":{"id":"dCE51NzTaLsA"},"source":["## Environment Setup"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4483,"status":"ok","timestamp":1681102687502,"user":{"displayName":"Srivarshan Selvaraj","userId":"15153016657166889388"},"user_tz":-330},"id":"KBUE3_jQaOB7","outputId":"ba3f08ce-98e9-4ca9-b3eb-8062bb58b321"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-04-10 04:58:03--  https://www.research.ibm.com/haifa/dept/vst/files/IBM_Debater_(R)_arg_quality_rank_30k.zip\n","Resolving www.research.ibm.com (www.research.ibm.com)... 52.116.220.135\n","Connecting to www.research.ibm.com (www.research.ibm.com)|52.116.220.135|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://research.ibm.com/haifa/dept/vst/files/IBM_Debater_(R)_arg_quality_rank_30k.zip [following]\n","--2023-04-10 04:58:03--  https://research.ibm.com/haifa/dept/vst/files/IBM_Debater_(R)_arg_quality_rank_30k.zip\n","Resolving research.ibm.com (research.ibm.com)... 52.116.220.135\n","Connecting to research.ibm.com (research.ibm.com)|52.116.220.135|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1524714 (1.5M) [application/zip]\n","Saving to: ‘IBM_Debater_(R)_arg_quality_rank_30k.zip’\n","\n","IBM_Debater_(R)_arg 100%[===================>]   1.45M  1.24MB/s    in 1.2s    \n","\n","2023-04-10 04:58:05 (1.24 MB/s) - ‘IBM_Debater_(R)_arg_quality_rank_30k.zip’ saved [1524714/1524714]\n","\n","Archive:  IBM_Debater_(R)_arg_quality_rank_30k.zip\n","  inflating: arg_quality_rank_30k.csv  \n","  inflating: readme.txt              \n"]}],"source":["# Download the dataset\n","\n","!rm arg_quality_rank_30k.csv\n","!wget \"https://www.research.ibm.com/haifa/dept/vst/files/IBM_Debater_(R)_arg_quality_rank_30k.zip\"\n","!unzip *.zip\n","!rm *.zip\n","!rm readme.txt"]},{"cell_type":"markdown","metadata":{"id":"8ZalZjf6aCLn"},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1681102687503,"user":{"displayName":"Srivarshan Selvaraj","userId":"15153016657166889388"},"user_tz":-330},"id":"B95wly28Z4V0","outputId":"e1e7b0fd-52b8-45a8-a088-387309498c4a"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","import re\n","import spacy\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from gensim.utils import simple_preprocess\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","\n","from sklearn.cluster import KMeans"]},{"cell_type":"markdown","metadata":{"id":"9fd3L_LgacNV"},"source":["## Seperating Using Avg"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1681102687504,"user":{"displayName":"Srivarshan Selvaraj","userId":"15153016657166889388"},"user_tz":-330},"id":"vVkNLDJNadSP","outputId":"4fc824d2-b583-4a93-9fd7-284568dae4dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Average WA is: 0.7913285945189035\n"]}],"source":["# Import dataset\n","df = pd.read_csv(\"./arg_quality_rank_30k.csv\")\n","\n","# Calculate mean\n","WA_mean = np.mean(df[\"WA\"])\n","print(f\"Average WA is: {WA_mean}\")\n","\n","# Convert into classes\n","df[\"class\"] = df[\"WA\"].apply(lambda x: 1 if x >= WA_mean else 0)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1681102687505,"user":{"displayName":"Srivarshan Selvaraj","userId":"15153016657166889388"},"user_tz":-330},"id":"jGDopIAfazxF","outputId":"1a16d74b-e441-4676-efa5-a5ed085944f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Length of dataset = 30497\n","Number of training data = 24182\n","Number of testing data = 6315\n","\n","Number of Topics = 71\n","Number of Topics in training data = 56\n","Number of Topics in testing data = 15\n","\n","Number of Classes = 2\n","Number of Class 0 in training data = 10009\n","Number of Class 0 in testing data = 2754\n","Number of Class 1 in training data = 14173\n","Number of Class 1 in testing data = 3561\n"]}],"source":["# Split into train and test sets\n","df_train = df[df[\"set\"] != \"test\"].reset_index(drop=True)\n","df_train = df_train.drop([\"set\"], axis=1)\n","df_test = df[df[\"set\"] == \"test\"].reset_index(drop=True)\n","df_test = df_test.drop([\"set\"], axis=1)\n","\n","# Display dataset metrics\n","print(f\"Length of dataset = {len(df)}\")\n","print(f\"Number of training data = {len(df_train)}\")\n","print(f\"Number of testing data = {len(df_test)}\")\n","print()\n","print(f\"Number of Topics = {len(np.unique(df.topic))}\")\n","print(f\"Number of Topics in training data = {len(np.unique(df_train.topic))}\")\n","print(f\"Number of Topics in testing data = {len(np.unique(df_test.topic))}\")\n","print()\n","print(f\"Number of Classes = {len(np.unique(df['class']))}\")\n","for label in np.unique(df[\"class\"]):\n","    print(f\"Number of Class {label} in training data = {len(df_train[df_train['class']==label])}\")\n","    print(f\"Number of Class {label} in testing data = {len(df_test[df_test['class']==label])}\")"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":133884,"status":"ok","timestamp":1681102821380,"user":{"displayName":"Srivarshan Selvaraj","userId":"15153016657166889388"},"user_tz":-330},"id":"JFrieaonb75q"},"outputs":[],"source":["# Text cleaning\n","stop_words = stopwords.words('english')\n","nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n","allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\"]\n","\n","def clean_text(text):\n","    text = text.lower()\n","    text = text.replace('</br>', '')\n","    text = text.replace('\\n', '')\n","    text = re.sub(r\"\\'\", \"\", text) \n","    text = re.sub(r\"\\\"\", \"\", text) \n","    text = re.sub(r\"[^\\w]\", \" \", text)\n","    text = re.sub(r'[ ]{2,}', ' ', text)\n","    text = re.sub(r'[ \\t]+$', '', text)\n","    text = simple_preprocess(str(text), deacc=True)\n","    tokens = []\n","    for token in text:\n","        if token not in stop_words:\n","            tokens.append(token)\n","    text = tokens\n","    text = \" \".join(text)\n","    text = nlp(text)\n","    lemmatized_tokens = []\n","    for token in text:\n","        if token.pos_ in allowed_postags:\n","            lemmatized_tokens.append(token.lemma_)\n","    text = lemmatized_tokens\n","    text = \" \".join(text)\n","    return text\n","\n","df_train[\"argument\"] = df_train[\"argument\"].apply(clean_text)\n","df_test[\"argument\"] = df_test[\"argument\"].apply(clean_text)"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":3755,"status":"ok","timestamp":1681102825131,"user":{"displayName":"Srivarshan Selvaraj","userId":"15153016657166889388"},"user_tz":-330},"id":"RF4-i6hpcUcl"},"outputs":[],"source":["# Build corpus using all texts\n","X = []\n","X.extend(df_train[\"argument\"].tolist())\n","X.extend(df_test[\"argument\"].tolist())\n","\n","# Fit vectorizer\n","vectorizer = CountVectorizer()\n","vectorizer = vectorizer.fit(X)\n","\n","# Transform the text\n","X = vectorizer.transform(X).toarray()\n","X_train = vectorizer.transform(df_train[\"argument\"]).toarray()\n","X_test = vectorizer.transform(df_test[\"argument\"]).toarray()\n","\n","# Target extraction\n","y = np.array(df[\"class\"])\n","y_train = np.array(df_train[\"class\"])\n","y_test = np.array(df_test[\"class\"])"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":76759,"status":"ok","timestamp":1681102901878,"user":{"displayName":"Srivarshan Selvaraj","userId":"15153016657166889388"},"user_tz":-330},"id":"HSc_YHGreCCF","outputId":"4083f279-58a7-40b8-f75a-451ebb14fa2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.50      0.64      0.56      2754\n","           1       0.65      0.51      0.57      3561\n","\n","    accuracy                           0.57      6315\n","   macro avg       0.57      0.58      0.57      6315\n","weighted avg       0.58      0.57      0.57      6315\n","\n"]}],"source":["# Train and evaluate basic logistic regression model\n","model = LogisticRegression(max_iter=1000)\n","history = model.fit(X_train, y_train)\n","pred = model.predict(X_test)\n","print(classification_report(y_test, pred))"]},{"cell_type":"markdown","metadata":{"id":"HbSKQSfJfX2S"},"source":["## Seperating Using Clustering"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1681102901879,"user":{"displayName":"Srivarshan Selvaraj","userId":"15153016657166889388"},"user_tz":-330},"id":"3ezDW03mfX2S"},"outputs":[],"source":["# Import dataset\n","df = pd.read_csv(\"./arg_quality_rank_30k.csv\")\n","\n","# Convert into classes\n","kmeans = KMeans(n_clusters=2, n_init=\"auto\", max_iter=1000, random_state=431)\n","X = np.array(df[\"WA\"]).reshape(-1, 1)\n","X = kmeans.fit_predict(X)\n","df[\"class\"] = X"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1681102901880,"user":{"displayName":"Srivarshan Selvaraj","userId":"15153016657166889388"},"user_tz":-330},"id":"d3CMJ1JTfX2T","outputId":"808b2fc4-5f4d-44d1-a3f9-cfd54854379a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Length of dataset = 30497\n","Number of training data = 24182\n","Number of testing data = 6315\n","\n","Number of Topics = 71\n","Number of Topics in training data = 56\n","Number of Topics in testing data = 15\n","\n","Number of Classes = 2\n","Number of Class 0 in training data = 6987\n","Number of Class 0 in testing data = 1979\n","Number of Class 1 in training data = 17195\n","Number of Class 1 in testing data = 4336\n"]}],"source":["# Split into train and test sets\n","df_train = df[df[\"set\"] != \"test\"].reset_index(drop=True)\n","df_train = df_train.drop([\"set\"], axis=1)\n","df_test = df[df[\"set\"] == \"test\"].reset_index(drop=True)\n","df_test = df_test.drop([\"set\"], axis=1)\n","\n","# Display dataset metrics\n","print(f\"Length of dataset = {len(df)}\")\n","print(f\"Number of training data = {len(df_train)}\")\n","print(f\"Number of testing data = {len(df_test)}\")\n","print()\n","print(f\"Number of Topics = {len(np.unique(df.topic))}\")\n","print(f\"Number of Topics in training data = {len(np.unique(df_train.topic))}\")\n","print(f\"Number of Topics in testing data = {len(np.unique(df_test.topic))}\")\n","print()\n","print(f\"Number of Classes = {len(np.unique(df['class']))}\")\n","for label in np.unique(df[\"class\"]):\n","    print(f\"Number of Class {label} in training data = {len(df_train[df_train['class']==label])}\")\n","    print(f\"Number of Class {label} in testing data = {len(df_test[df_test['class']==label])}\")"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":134084,"status":"ok","timestamp":1681103035957,"user":{"displayName":"Srivarshan Selvaraj","userId":"15153016657166889388"},"user_tz":-330},"id":"qzFUOvB_fX2U"},"outputs":[],"source":["# Text cleaning\n","stop_words = stopwords.words('english')\n","nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n","allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\"]\n","\n","def clean_text(text):\n","    text = text.lower()\n","    text = text.replace('</br>', '')\n","    text = text.replace('\\n', '')\n","    text = re.sub(r\"\\'\", \"\", text) \n","    text = re.sub(r\"\\\"\", \"\", text) \n","    text = re.sub(r\"[^\\w]\", \" \", text)\n","    text = re.sub(r'[ ]{2,}', ' ', text)\n","    text = re.sub(r'[ \\t]+$', '', text)\n","    text = simple_preprocess(str(text), deacc=True)\n","    tokens = []\n","    for token in text:\n","        if token not in stop_words:\n","            tokens.append(token)\n","    text = tokens\n","    text = \" \".join(text)\n","    text = nlp(text)\n","    lemmatized_tokens = []\n","    for token in text:\n","        if token.pos_ in allowed_postags:\n","            lemmatized_tokens.append(token.lemma_)\n","    text = lemmatized_tokens\n","    text = \" \".join(text)\n","    return text\n","\n","df_train[\"argument\"] = df_train[\"argument\"].apply(clean_text)\n","df_test[\"argument\"] = df_test[\"argument\"].apply(clean_text)"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":2948,"status":"ok","timestamp":1681103038899,"user":{"displayName":"Srivarshan Selvaraj","userId":"15153016657166889388"},"user_tz":-330},"id":"ypbQ_NcffX2V"},"outputs":[],"source":["# Build corpus using all texts\n","X = []\n","X.extend(df_train[\"argument\"].tolist())\n","X.extend(df_test[\"argument\"].tolist())\n","\n","# Fit vectorizer\n","vectorizer = CountVectorizer()\n","vectorizer = vectorizer.fit(X)\n","\n","# Transform the text\n","X = vectorizer.transform(X).toarray()\n","X_train = vectorizer.transform(df_train[\"argument\"]).toarray()\n","X_test = vectorizer.transform(df_test[\"argument\"]).toarray()\n","\n","# Target extraction\n","y = np.array(df[\"class\"])\n","y_train = np.array(df_train[\"class\"])\n","y_test = np.array(df_test[\"class\"])"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I35FC-w8fX2V","executionInfo":{"status":"ok","timestamp":1681103103784,"user_tz":-330,"elapsed":64888,"user":{"displayName":"Srivarshan Selvaraj","userId":"15153016657166889388"}},"outputId":"018029df-8060-4cff-a31d-55f7434ffc57"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.43      0.40      0.42      1979\n","           1       0.73      0.76      0.75      4336\n","\n","    accuracy                           0.64      6315\n","   macro avg       0.58      0.58      0.58      6315\n","weighted avg       0.64      0.64      0.64      6315\n","\n"]}],"source":["# Train and evaluate basic logistic regression model\n","model = LogisticRegression(max_iter=1000)\n","history = model.fit(X_train, y_train)\n","pred = model.predict(X_test)\n","print(classification_report(y_test, pred))"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPU7xJZzlJAlV03HSCM7hYH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}